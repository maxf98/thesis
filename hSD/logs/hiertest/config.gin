hierarchical_skill_discovery.num_layers = 2
hierarchical_skill_discovery.skill_lengths = (20,20)
hierarchical_skill_discovery.log_dir = "/Users/maxfest/RL/thesis/hSD/logs/hiertest"

get_base_env.env_name = "point_env"
get_base_env.point_env_step_size = 0.05

initialise_skill_discovery_agent.objective = 's->z'
initialise_skill_discovery_agent.skill_prior = 'cont_uniform'
initialise_skill_discovery_agent.skill_dim = 2

init_rollout_driver.online_buffer_size = (4000, 200)  #should be equal to collect_steps, technically we shouldn't make this an independent parameter
init_rollout_driver.offline_buffer_size = (10000, 500)
init_rollout_driver.episode_length = (100, 100)
init_rollout_driver.state_norm = True

BaseSkillModel.fc_layer_params = (128, 128)
BaseSkillModel.fix_variance = True  # only continuous skill models

SACLearner.fc_layer_params = (128, 128)
SACLearner.alpha_loss_weight = 0  # if set to 0, not learning alpha variable, i.e. no EC-SAC
SACLearner.initial_entropy = 3.0
SACLearner.target_entropy = 0.1
SACLearner.entropy_anneal_steps = 10000
SACLearner.entropy_anneal_period = None

Logger.create_fig_interval = 10
Logger.num_samples_per_skill = 3

train_skill_discovery.num_epochs=(2,1)
train_skill_discovery.initial_collect_steps=(400, 20)
train_skill_discovery.collect_steps_per_epoch=(400, 20)
train_skill_discovery.batch_size=(64, 16)
train_skill_discovery.skill_model_train_steps=(128, 32)
train_skill_discovery.policy_learner_train_steps=(256, 16)
