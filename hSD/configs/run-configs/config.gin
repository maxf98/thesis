hierarchical_skill_discovery.num_layers = 1
hierarchical_skill_discovery.skill_lengths = (5,)

init_experiment_logger.log_dir = "logs/diayn/thesis/test"

get_base_env.env_name = "point_env"
get_base_env.point_env_step_size = 0.1
get_base_env.point_env_box_size = 1

initialise_skill_discovery_agent.objective = 's->z'
initialise_skill_discovery_agent.skill_prior = 'cont_uniform'
initialise_skill_discovery_agent.skill_dim = 2

init_rollout_driver.buffer_size = 1000
init_rollout_driver.episode_length = 5
init_rollout_driver.state_norm = True

init_skill_model.hidden_dim = (128, 128)
init_skill_model.fix_variance = True  # only continuous skill models

init_policy_learner.rl_alg = 'SAC'
init_policy_learner.fc_layer_params = (128, 128)
init_policy_learner.target_entropy = None  # for EC-SAC, default is something like -1/dim(A)
init_policy_learner.reward_scale_factor = 1.0
init_policy_learner.alpha_loss_weight = 0.0  # if set to 0, fixed entropy version of SAC

init_logger.create_fig_interval = 1
init_logger.num_samples_per_skill = 3

train.num_epochs=100
train.initial_collect_steps=1000
train.collect_steps_per_epoch=1000
train.batch_size=64
train.skill_model_train_steps=64
train.policy_learner_train_steps=128
