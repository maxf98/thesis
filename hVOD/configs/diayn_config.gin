
# LAUNCHER
run_experiment.num_skills = 4

# SAC
init_sac_agent.learning_rate = 3e-4
init_sac_agent.target_update_tau = 0.005 # @param {type:"number"}
init_sac_agent.target_update_period = 1 # @param {type:"number"}
init_sac_agent.gamma = 0.99 # @param {type:"number"}
init_sac_agent.reward_scale_factor = 1.0 # @param {type:"number"}

init_sac_agent.actor_fc_layer_params = (256, 256)
init_sac_agent.critic_joint_fc_layer_params = (256, 256)

# SKILL DISCOVERY
train_skill_discovery.num_epochs = 100
train_skill_discovery.initial_collect_steps = 10000
train_skill_discovery.collect_steps_per_epoch = 2000  # turn into collect_episodes ?
train_skill_discovery.dynamics_train_steps_per_epoch = 256
train_skill_discovery.sac_train_steps_per_epoch = 256

# DISCRIMINATOR
init_skill_discriminator.intermediate_dim = 128

# BUFFER
init_buffer.buffer_size = 10000

# LOGGING
init_logging.log_dir = '../../logs/diayn'
init_logging.create_fig_interval = 5
